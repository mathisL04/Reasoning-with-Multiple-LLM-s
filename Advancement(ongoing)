# 🧠 Reasoning with Multiple LLMs

## 🧪 Project Overview

This project explores the potential of **collaborative reasoning between large language models (LLMs)**, focusing on how alternating dialogue and structured interaction can improve problem-solving performance. We implemented a **biased collaborative setting**, where two models interact sequentially:

- **LLM1 (OpenAI o3-mini)** starts the conversation.
- **LLM2 (Together AI's Qwen/QwQ-32B)** finishes it, giving the final answer.

Each model engages in **two chat turns**, making a total of four exchanges per problem. The task is tested on **GSM8K**, a benchmark of grade-school math problems known for its structured, step-by-step reasoning format.

---

## ⚙️ Experimental Setup

- **Benchmark:** [GSM8K](https://huggingface.co/datasets/gsm8k)
- **Turns per Model:** 2 (Total: 4 per interaction)
- **Collaborative Strategy:** Turn-based dialogue, with LLM2 always concluding
- **Evaluation Metric:** Accuracy (numerical matching to ground truth)

---

## 📊 Performance Summary

| Sample Size | OpenAI (LLM1) | Together AI (LLM2) | Collaborative (i = 2) |
|-------------|---------------|--------------------|------------------------|
| 1           | 100%          | 100%               | 100%                   |
| 10          | 100%          | 80%                | **100%**               |
| 25          | 100%          | 72%                | **100%**               |
| 50          | 96%           | 68.6%              | **94%**                |
| 100         | 95%           | 58%                | **92%**                |

> Note: Temperature for Together AI was fixed at `0.7`. All models used the same prompt format and problem set for fairness.

---

## 🧭 Interpretation

The collaboration often **outperforms the weaker individual model** (Together AI) and occasionally **boosts performance beyond even the stronger model** (OpenAI), particularly on larger sample sizes. This suggests that **turn-based reasoning helps reinforce correct steps**, especially when models can "rethink" based on the previous turn.

While this collaboration is **asymmetric** (LLM1 always begins, LLM2 always ends), it demonstrates **robustness to early inaccuracies** and some degree of complementary skill use between models.

---

## 📌 Limitations & Next Steps

- **Biased Setup:** The first and final turns are always assigned to specific models. This asymmetry may influence results.
- **Trivial Benchmark:** GSM8K's math problems are relatively simple and deterministic. Future work should incorporate:
  - **AIME (American Invitational Math Exam)**
  - **MATH Dataset (advanced high school math)**
  - **AQUA-RAT, SVAMP, ASDiv** (algebra and multi-step logic)

---

## 🔮 Future Directions

- ✅ Vary number of dialogue rounds (e.g., 3–5 total exchanges)
- ✅ Alternate which model begins or ends the interaction
- 🧪 Introduce a third model to **judge or score** final outputs
- 🔄 Try **voting or majority aggregation** across multiple LLM outputs
- ⚖️ Score open-ended responses using **subjective evaluation metrics** (e.g., logical coherence, coverage, confidence)
